# -*- coding: utf-8 -*-
"""Copy of DBS ILT 7: Predictive Analytics

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1F706eAbFqlS9KxMlmjot9GsnczNJvwE5

# Domain Proyek

Diabetes adalah penyakit metabolik kronis yang berdampak besar pada kualitas hidup dan sistem kesehatan masyarakat. Seiring berjalannya waktu, prevalensi diabetes terus meningkat di berbagai negara. Berdasarkan data WHO, diabetes telah menjadi salah satu penyebab utama kematian dini dan beban biaya kesehatan yang signifikan. Oleh karena itu, penting untuk melakukan deteksi dini terhadap risiko diabetes guna menghindari komplikasi yang lebih parah di masa depan.

Proyek ini bertujuan untuk mengembangkan model klasifikasi guna memprediksi risiko diabetes berdasarkan sejumlah indikator gaya hidup dan kondisi kesehatan, seperti pola makan, tingkat stres, konsumsi air, serta kepatuhan terhadap pengobatan.

# Business Understanding

**Problem Statement :**

1.   Bagaimana cara memanfaatkan informasi pola hidup guna memprediksi kategori diabetes pada seseorang?
2.   Apa faktor-faktor yang paling berkontribusi terhadap peningkatan risiko diabetes?

**Goals :**

1.   Membangun model klasifikasi untuk memprediksi risiko diabetes
2.   Mengidentifikasi fitur-fitur gaya hidup yang memiliki kontribusi paling besar terhadap peningkatan risiko diabetes, berdasarkan hasil pemodelan machine learning.

**Solution Statement :**

1.   Menerapkan beberapa algoritma machine learning seperti Decision Tree, dan Random Forest, serta membandingkan performa masing-masing model menggunakan metrik akurasi, precision, recall, dan f1-score.
2.   Menganalisis kontribusi setiap fitur input terhadap prediksi risiko diabetes menggunakan teknik seperti feature importance.

# Data Understanding

**Sumber Dataset**

Dataset diperoleh dari Kaggle:
ðŸ”— [Diabetes Dataset â€“ Akshay Dattatray Khare](https://www.kaggle.com/datasets/akshaydattatraykhare/diabetes-dataset)

**Deskripsi Data**

Dataset ini berisi informasi medis dari pasien perempuan keturunan Pima Indian yang digunakan untuk memprediksi risiko diabetes. Fitur-fitur yang tersedia mencerminkan faktor-faktor kesehatan yang relevan, antara lain:

* `Pregnancies` : Jumlah kehamilan yang pernah dialami.
* `Glucose` : Konsentrasi glukosa plasma saat puasa (mg/dL).
* `BloodPressure` : Tekanan darah diastolik (mm Hg).
* `SkinThickness` : Ketebalan lipatan kulit triceps (mm).
* `Insulin` : Kadar insulin serum 2 jam (mu U/ml).
* `BMI` : Indeks massa tubuh (berat badan dalam kg dibagi kuadrat tinggi badan dalam m).
* `DiabetesPedigreeFunction` : Nilai fungsi silsilah diabetes (menggambarkan kemungkinan diabetes berdasarkan riwayat keluarga).
* `Age` : Usia pasien (tahun).
* `Outcome` : Label target (0 = tidak diabetes, 1 = diabetes).

# Data Loading
"""

# Commented out IPython magic to ensure Python compatibility.
import numpy as np
import matplotlib.pyplot as plt
import pandas as pd
# %matplotlib inline
import seaborn as sns

#!/bin/bash
!curl -L -o diabetes-dataset.zip\
  https://www.kaggle.com/api/v1/datasets/download/akshaydattatraykhare/diabetes-dataset

!unzip diabetes-dataset.zip

df = pd.read_csv('diabetes.csv')
df.head()

"""# Exploratory Data Analysis - Deskripsi Variabel

Cakupan proses EDA sangat luas. Namun, secara umum, Anda dapat melakukan proses EDA untuk menjawab beberapa pertanyaan berikut:
- Apa saja jenis variabel pada dataset?
- Bagaimana distribusi variabel dalam dataset?
- Apakah ada missing value?
- Apakah ada fitur yang tidak berguna (redundant)?
- Bagaimana korelasi antara fitur dan target?

Deskripsi Variabel
Berdasarkan informasi dari Kaggle, variabel-variabel pada Diamond dataset adalah sebagai berikut:


* `Pregnancies` : Jumlah kehamilan yang pernah dialami.
* `Glucose` : Konsentrasi glukosa plasma saat puasa (mg/dL).
* `BloodPressure` : Tekanan darah diastolik (mm Hg).
* `SkinThickness` : Ketebalan lipatan kulit triceps (mm).
* `Insulin` : Kadar insulin serum 2 jam (mu U/ml).
* `BMI` : Indeks massa tubuh (berat badan dalam kg dibagi kuadrat tinggi badan dalam m).
* `DiabetesPedigreeFunction` : Nilai fungsi silsilah diabetes (menggambarkan kemungkinan diabetes berdasarkan riwayat keluarga).
* `Age` : Usia pasien (tahun).
* `Outcome` : Label target (0 = tidak diabetes, 1 = diabetes).
"""

df.info()

df.describe()

"""## Menangani Missing Value"""

df.isnull().sum()

"""## Menangani Duplicate"""

df.duplicated().sum()

"""## Menangani Outliers"""

# Deteksi Outlier dengan metode IQR
def detect_outliers(data):
    outlier_summary = {}
    for column in data.select_dtypes(include=np.number).columns:
        Q1 = data[column].quantile(0.25)
        Q3 = data[column].quantile(0.75)
        IQR = Q3 - Q1
        lower_bound = Q1 - 1.5 * IQR
        upper_bound = Q3 + 1.5 * IQR
        outliers = data[(data[column] < lower_bound) | (data[column] > upper_bound)]
        outlier_summary[column] = len(outliers)

    return outlier_summary

# Menjalankan fungsi untuk dataset (tanpa kolom target)
indicators_columns = df.drop(columns=['risk_score'], errors='ignore')
outlier_counts = detect_outliers(indicators_columns)

# Menampilkan jumlah outlier per kolom
print("Jumlah outlier per kolom:")
for col, count in outlier_counts.items():
    print(f"{col}: {count}")

# Mengelompokkan fitur numerik kecuali kolom target 'outcome'
indicators_feature = df.select_dtypes(include=np.number).drop(columns=['Outcome'], errors='ignore').columns

import math

# Hitung jumlah baris dan kolom dinamis (misalnya grid 4x2 atau 3x4 tergantung jumlah fitur)
n_features = len(indicators_feature)
n_cols = 2
n_rows = math.ceil(n_features / n_cols)

# Buat grid
fig, axes = plt.subplots(nrows=n_rows, ncols=n_cols, figsize=(12, n_rows * 3))
fig.suptitle('Boxplot of Numerical Features', fontsize=16)

# Flatten axes supaya bisa di-loop
axes = axes.flatten()

# Plot tiap fitur
for i, feature in enumerate(indicators_feature):
    sns.boxplot(data=df, x=feature, ax=axes[i])
    axes[i].set_title(f'{feature}')
    axes[i].set_xlabel('')

# Sembunyikan subplot kosong
for j in range(len(indicators_feature), len(axes)):
    fig.delaxes(axes[j])

plt.tight_layout(rect=[0, 0, 1, 0.96])
plt.show()

# Fungsi untuk menghapus outlier dengan metode IQR
df_clean = df.copy()
def remove_outliers(df, columns):
    df_clean = df.copy()
    for col in columns:
        Q1 = df_clean[col].quantile(0.25)
        Q3 = df_clean[col].quantile(0.75)
        IQR = Q3 - Q1
        lower_bound = Q1 - 1.5 * IQR
        upper_bound = Q3 + 1.5 * IQR
        df_clean = df_clean[(df_clean[col] >= lower_bound) & (df_clean[col] <= upper_bound)]
    return df_clean

# Hapus outlier
df_clean = remove_outliers(df_clean, indicators_feature)

# Tampilkan informasi perubahan
print("Outlier Berhasil Dihapus")

print(f"Jumlah baris sebelum data cleansing: {df.shape[0]}")
print(f"Jumlah baris sesudah data cleansing: {df_clean.shape[0]}")

"""## Univariate Analysis"""

df_clean.hist(bins=50, figsize=(20,15))
plt.tight_layout()
plt.show()

"""## Multivariate Analysis"""

# Mengamati hubungan antar fitur numerik dengan fungsi pairplot()
sns.pairplot(df_clean, diag_kind = 'kde')

plt.figure(figsize=(10, 8))
correlation_matrix = df_clean.corr().round(2)

# Untuk menge-print nilai di dalam kotak, gunakan parameter anot=True
sns.heatmap(data=correlation_matrix, annot=True, cmap='coolwarm', linewidths=0.5, )
plt.title("Correlation Matrix untuk Fitur Numerik ", size=20)

"""# Data Preparation

## Train Test Split
"""

from sklearn.model_selection import train_test_split
from sklearn.preprocessing import MinMaxScaler
from sklearn.decomposition import PCA
from imblearn.over_sampling import SMOTE

X = df_clean.drop(columns=["Outcome"])
y = df_clean["Outcome"]

scaler = MinMaxScaler()
X_scaler = scaler.fit_transform(X)

smote = SMOTE(random_state=42)
X_resampled, y_resampled = smote.fit_resample(X_scaler, y)

pca = PCA(n_components= 0.95)
X_pca = pca.fit_transform(X_resampled)

X_train, X_test, y_train, y_test = train_test_split(X_pca, y_resampled, test_size= 0.2, random_state= 42)

print(f'Total # of sample in train dataset: {len(X_train)}')
print(f'Total # of sample in test dataset: {len(X_test)}')

"""# Training Model

Pada tahap ini, kita akan mengembangkan model machine learning dengan dua algoritma. Kemudian, kita akan mengevaluasi performa masing-masing algoritma dan menentukan algoritma mana yang memberikan hasil prediksi terbaik. Kedua algoritma yang akan kita gunakan, antara lain:

- Random Forest
- Decission Tree

## Random Forest
"""

from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import accuracy_score, classification_report
from sklearn.model_selection import cross_val_score

rf = RandomForestClassifier(n_estimators=100, max_depth=10,
                           min_samples_leaf=5, random_state=42)
rf.fit(X_train, y_train)
y_train_rf = rf.predict(X_train)
y_test_rf = rf.predict(X_test)
train_acc = accuracy_score(y_train, y_train_rf)
test_acc = accuracy_score(y_test, y_test_rf)
cv_scores = cross_val_score(rf, X_train, y_train, cv=5)

print(f"Accuracy Data Training: {train_acc:.2f}")
print(f"Accuracy Data Testing: {test_acc:.2f}")
print(f"Mean CV Score:{cv_scores.mean():.2f}")
print(classification_report(y_test, y_test_rf))

"""## Decission Tree"""

from sklearn.tree import DecisionTreeClassifier
from sklearn.metrics import confusion_matrix

dt = DecisionTreeClassifier(max_depth=10, random_state=42)
dt.fit(X_train, y_train)
y_train_dt = dt.predict(X_train)
y_test_dt = dt.predict(X_test)

train_acc_dt = accuracy_score(y_train, y_train_dt)
test_acc_dt = accuracy_score(y_test, y_test_dt)
cv_scores_dt = cross_val_score(dt, X_train, y_train, cv=5)

print(f"Accuracy Data Training: {train_acc_dt:.2f}")
print(f"Accuracy Data Testing: {test_acc_dt:.2f}")
print(f"Mean CV Score:{cv_scores_dt.mean():.2f}")
print(classification_report(y_test, y_test_dt))

"""# Perbandingan Model"""

# Perbandingan akurasi
acc_rf = accuracy_score(y_test, y_test_rf)
acc_dt = accuracy_score(y_test, y_test_dt)

print(f"Akurasi Random Forest: {acc_rf:.3f}")
print(f"Akurasi Decision Tree: {acc_dt:.3f}")

from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score

# Dictionary untuk menyimpan hasil evaluasi
model_scores = {}

# Fungsi evaluasi dan pencatatan skor
def evaluate_and_store(model, X_train, y_train, X_test, y_test, model_name):
    model.fit(X_train, y_train)
    y_pred = model.predict(X_test)

    # Simpan skor dalam dictionary
    model_scores[model_name] = {
        'Accuracy': accuracy_score(y_test, y_pred),
        'Precision': precision_score(y_test, y_pred, average='macro'),
        'Recall': recall_score(y_test, y_pred, average='macro'),
        'F1 Score': f1_score(y_test, y_pred, average='macro')
    }

# Evaluasi semua model
from sklearn.ensemble import RandomForestClassifier
from sklearn.tree import DecisionTreeClassifier

# Random Forest
rf_model = RandomForestClassifier(random_state=42)
evaluate_and_store(rf_model, X_train, y_train, X_test, y_test, "Random Forest")

# Decision Tree
dt_model = DecisionTreeClassifier(random_state=42)
evaluate_and_store(dt_model, X_train, y_train, X_test, y_test, "Decision Tree")

# Menampilkan hasil perbandingan
import pandas as pd

results_df = pd.DataFrame(model_scores).T
results_df = results_df.sort_values(by="Accuracy", ascending=False)  # Urutkan berdasarkan akurasi
print("ðŸ“Š Hasil Perbandingan Model:\n")
print(results_df)

# Opsional: visualisasi
import seaborn as sns
import matplotlib.pyplot as plt

plt.figure(figsize=(10, 6))
sns.barplot(data=results_df.reset_index().melt(id_vars='index'), x='index', y='value', hue='variable')
plt.title("Perbandingan Performa Model")
plt.xlabel("Model")
plt.ylabel("Skor")
plt.xticks(rotation=45)
plt.legend(title="Metric")
plt.tight_layout()
plt.show()

"""Dari keempat diagram, Decision Tree mengungguli Random Forest dalam seluruh aspek. Hal ini menjadikan Decision Tree sebagai model yang lebih baik secara keseluruhan.

Model Decision Tree adalah model terbaik dalam studi ini karena mampu memberikan:


*  Akurasi yang tinggi
*  Precision yang sangat baik
*   Keseimbangan recall dan F1 score

# Fitur

## Prediksi hasil diabetes berdasarkan inputan yang diberikan
"""

import numpy as np
import pandas as pd

def infer_diabetes_risk(model, scaler, pca):
    print("Masukkan data berikut untuk memprediksi risiko diabetes Anda:\n")

    try:
        pregnancies = int(input("Jumlah kehamilan: "))
        glucose = float(input("Kadar glukosa darah (mg/dL): "))
        blood_pressure = float(input("Tekanan darah (mm Hg): "))
        skin_thickness = float(input("Ketebalan lipatan kulit triceps (mm): "))
        insulin = float(input("Kadar insulin (mu U/ml): "))
        bmi = float(input("BMI (Indeks Massa Tubuh): "))
        dpf = float(input("Fungsi silsilah diabetes (Diabetes Pedigree Function): "))
        age = int(input("Usia: "))

        fitur_input = pd.DataFrame([[
            pregnancies, glucose, blood_pressure, skin_thickness,
            insulin, bmi, dpf, age
        ]], columns=[
            'Pregnancies', 'Glucose', 'BloodPressure', 'SkinThickness',
            'Insulin', 'BMI', 'DiabetesPedigreeFunction', 'Age'
        ])

        fitur_input_scaled = scaler.transform(fitur_input)
        fitur_input_pca = pca.transform(fitur_input_scaled)

        pred_label = model.predict(fitur_input_pca)

        hasil = "Positif (berisiko)" if pred_label[0] == 1 else "Negatif (tidak berisiko)"
        print("\nðŸ“Š Prediksi hasil diabetes Anda adalah:", hasil)

    except ValueError:
        print("Input tidak valid. Pastikan Anda memasukkan angka.")
    except Exception as e:
        print(f"Terjadi kesalahan: {e}")

infer_diabetes_risk(dt_model, scaler, pca)

"""## Korelasi antar fitur numerik dengan hasil yang didapat"""

# Hitung korelasi antar fitur numerik terhadap 'Outcome'
correlation_matrix = df_clean.corr(numeric_only=True)
cor_target = correlation_matrix['Outcome'].drop('Outcome').sort_values(ascending=False)

print("ðŸ“Š Korelasi fitur terhadap 'Outcome':")
print(cor_target)

# Ambil fitur dengan korelasi absolut > 0.3
important_features = cor_target[cor_target.abs() > 0.25]
print("\nðŸ”¥ Fitur dengan pengaruh signifikan (|korelasi| > 0.3):")
print(important_features)