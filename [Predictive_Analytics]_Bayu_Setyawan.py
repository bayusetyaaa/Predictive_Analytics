# -*- coding: utf-8 -*-
"""Copy of DBS ILT 7: Predictive Analytics

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1F706eAbFqlS9KxMlmjot9GsnczNJvwE5

# Domain Proyek

Diabetes adalah penyakit metabolik kronis yang berdampak besar pada kualitas hidup dan sistem kesehatan masyarakat. Seiring berjalannya waktu, prevalensi diabetes terus meningkat di berbagai negara. Berdasarkan data WHO, diabetes telah menjadi salah satu penyebab utama kematian dini dan beban biaya kesehatan yang signifikan. Oleh karena itu, penting untuk melakukan deteksi dini terhadap risiko diabetes guna menghindari komplikasi yang lebih parah di masa depan.

Proyek ini bertujuan untuk mengembangkan model klasifikasi guna memprediksi risiko diabetes berdasarkan sejumlah indikator gaya hidup dan kondisi kesehatan, seperti pola makan, tingkat stres, konsumsi air, serta kepatuhan terhadap pengobatan.

# Business Understanding

**Problem Statement :**

1.   Bagaimana cara memanfaatkan informasi pola hidup guna memprediksi kategori diabetes pada seseorang?
2.   Apa faktor-faktor yang paling berkontribusi terhadap peningkatan risiko diabetes?

**Goals :**

1.   Membangun model klasifikasi untuk memprediksi risiko diabetes
2.   Mengidentifikasi fitur-fitur gaya hidup yang memiliki kontribusi paling besar terhadap peningkatan risiko diabetes, berdasarkan hasil pemodelan machine learning.

**Solution Statement :**

1.   Menerapkan beberapa algoritma machine learning seperti Decision Tree, dan Random Forest, serta membandingkan performa masing-masing model menggunakan metrik akurasi, precision, recall, dan f1-score.
2.   Menganalisis kontribusi setiap fitur input terhadap prediksi risiko diabetes menggunakan teknik seperti feature importance.

# Data Understanding

**Sumber Dataset**

Dataset diperoleh dari Kaggle:
ğŸ”— [Diabetes Dataset â€“ Akshay Dattatray Khare](https://www.kaggle.com/datasets/akshaydattatraykhare/diabetes-dataset)

**Deskripsi Data**

Dataset ini berisi informasi medis dari pasien perempuan keturunan Pima Indian yang digunakan untuk memprediksi risiko diabetes. Fitur-fitur yang tersedia mencerminkan faktor-faktor kesehatan yang relevan, antara lain:

* `Pregnancies` : Jumlah kehamilan yang pernah dialami.
* `Glucose` : Konsentrasi glukosa plasma saat puasa (mg/dL).
* `BloodPressure` : Tekanan darah diastolik (mm Hg).
* `SkinThickness` : Ketebalan lipatan kulit triceps (mm).
* `Insulin` : Kadar insulin serum 2 jam (mu U/ml).
* `BMI` : Indeks massa tubuh (berat badan dalam kg dibagi kuadrat tinggi badan dalam m).
* `DiabetesPedigreeFunction` : Nilai fungsi silsilah diabetes (menggambarkan kemungkinan diabetes berdasarkan riwayat keluarga).
* `Age` : Usia pasien (tahun).
* `Outcome` : Label target (0 = tidak diabetes, 1 = diabetes).

# Data Loading

Import Library
"""

# Commented out IPython magic to ensure Python compatibility.
import numpy as np
import matplotlib.pyplot as plt
import pandas as pd
# %matplotlib inline
import seaborn as sns

"""Import Dataset dari Kaggle"""

#!/bin/bash
!curl -L -o diabetes-dataset.zip\
  https://www.kaggle.com/api/v1/datasets/download/akshaydattatraykhare/diabetes-dataset

"""melakukan unzip dataset yang diimport"""

!unzip diabetes-dataset.zip

"""Membaca file CSV bernama 'diabetes.csv' dan menyimpannya ke dalam DataFrame bernama df"""

df = pd.read_csv('diabetes.csv')
df.head()

"""# Exploratory Data Analysis - Deskripsi Variabel

Cakupan proses EDA sangat luas. Namun, secara umum, Anda dapat melakukan proses EDA untuk menjawab beberapa pertanyaan berikut:
- Apa saja jenis variabel pada dataset?
- Bagaimana distribusi variabel dalam dataset?
- Apakah ada missing value?
- Apakah ada fitur yang tidak berguna (redundant)?
- Bagaimana korelasi antara fitur dan target?

Deskripsi Variabel
Berdasarkan informasi dari Kaggle, variabel-variabel pada Diamond dataset adalah sebagai berikut:


* `Pregnancies` : Jumlah kehamilan yang pernah dialami.
* `Glucose` : Konsentrasi glukosa plasma saat puasa (mg/dL).
* `BloodPressure` : Tekanan darah diastolik (mm Hg).
* `SkinThickness` : Ketebalan lipatan kulit triceps (mm).
* `Insulin` : Kadar insulin serum 2 jam (mu U/ml).
* `BMI` : Indeks massa tubuh (berat badan dalam kg dibagi kuadrat tinggi badan dalam m).
* `DiabetesPedigreeFunction` : Nilai fungsi silsilah diabetes (menggambarkan kemungkinan diabetes berdasarkan riwayat keluarga).
* `Age` : Usia pasien (tahun).
* `Outcome` : Label target (0 = tidak diabetes, 1 = diabetes).

Menampilkan informasi umum tentang DataFrame, termasuk jumlah entri, jumlah kolom, nama kolom, tipe data, dan jumlah nilai non-null
"""

df.info()

"""Menampilkan statistik deskriptif dari setiap kolom numerik dalam DataFrame,termasuk nilai count, mean, std (standard deviation), min, 25%, 50% (median), 75%, dan max."""

df.shape

"""Melihat statistik deskriptif dari dataset."""

df.describe()

"""Menampilkan jumlah data (count), nilai rata-rata (mean), standar deviasi (std), nilai minimum, kuartil (25%, 50%, 75%), dan nilai maksimum untuk setiap kolom numerik.

## Menangani Missing Value

Mengecek jumlah missing values pada setiap kolom di DataFrame.
"""

df.isnull().sum()

"""berdasarkan hasil pengecekan dapat diinfokan bahwa tidak terdapat missing value

## Menangani Duplicate

Mengecek jumlah missing values pada setiap kolom di DataFrame.
"""

df.duplicated().sum()

"""berdasarkan hasil pengecekan dapat diinfokan bahwa tidak terdapat missing value

## Univariate Analysis

Menampilkan distribusi data untuk setiap fitur numerik dalam bentuk histogram.
"""

df_clean.hist(bins=50, figsize=(20,15))
plt.tight_layout()
plt.show()

"""## Multivariate Analysis

Mengamati hubungan antar fitur numerik dengan fungsi pairplot()
"""

sns.pairplot(df_clean, diag_kind = 'kde')

"""Menampilkan matriks korelasi antar fitur numerik dalam bentuk heatmap"""

plt.figure(figsize=(10, 8))
correlation_matrix = df_clean.corr().round(2)

# Untuk menge-print nilai di dalam kotak, gunakan parameter anot=True
sns.heatmap(data=correlation_matrix, annot=True, cmap='coolwarm', linewidths=0.5, )
plt.title("Correlation Matrix untuk Fitur Numerik ", size=20)

"""Berdasarkan visualisasi dan matriks korelasi tersebut dapat diketahui bahwa:
**1. Glucose**
* **Korelasi tertinggi dengan Outcome (0.49)** â†’ menunjukkan bahwa kadar glukosa yang lebih tinggi berhubungan dengan kemungkinan lebih besar menderita diabetes.
* Juga berkorelasi dengan **Insulin (0.28)** dan **BloodPressure (0.23)**.
* Kesimpulan: Glukosa merupakan fitur prediktor penting untuk Outcome.


 **BMI (Body Mass Index)**

* Korelasi sedang dengan **Outcome (0.27)**.
* Korelasi positif dengan **SkinThickness (0.38)** dan **BloodPressure (0.29)**.
* Kesimpulan: BMI juga punya peran penting dalam memprediksi diabetes.


 **Pregnancies (Jumlah Kehamilan)**

* Korelasi sedang dengan **Age (0.58)** â†’ logis karena semakin tua biasanya jumlah kehamilan meningkat.
* Korelasi sedang dengan **Outcome (0.24)**.
* Kesimpulan: Fitur ini lebih relevan secara demografis, tapi tetap memberi informasi dalam klasifikasi.

 **Age (Usia)**

* Korelasi sedang dengan **Pregnancies (0.58)** dan **Outcome (0.27)**.
* Korelasi rendah dengan fitur lain.
* Kesimpulan: Usia juga relevan untuk klasifikasi, tapi tidak sekuat Glucose atau BMI.


**Insulin**

* Korelasi kuat dengan **SkinThickness (0.48)**.
* Korelasi sedang dengan **Glucose (0.28)**.

**SkinThickness**

* Korelasi sedang dengan **Insulin (0.48)** dan **BMI (0.38)**.
* Korelasi rendah dengan Outcome (0.04).

**BloodPressure**

* Korelasi sedang dengan **BMI (0.29)** dan **Age (0.35)**.
* Korelasi rendah dengan Outcome (0.17).


**DiabetesPedigreeFunction**

* Korelasi sangat rendah dengan fitur lain.
* Korelasi rendah dengan Outcome (0.17).

# Data Preparation

## Menangani Outliers

Dari visualisasi diatas dapat diinterpretasikan bahwa :
* Pregnancies: Mayoritas responden memiliki 0â€“2 kehamilan, dengan puncaknya pada 1 kehamilan.
* Glucose: Mayoritas kadar glukosa berada di kisaran 90â€“130 mg/dL, dengan puncak sekitar 110â€“120 mg/dL.
* BloodPressure: Mayoritas tekanan darah berada di kisaran 60â€“80 mmHg, dengan puncak sekitar 70 mmHg.
* SkinThickness: Distribusi cukup tersebar, namun terdapat banyak nilai 0 yang menandakan kemungkinan data kosong/tidak diukur. Nilai terbanyak setelah 0 berada pada kisaran 20â€“40 mm.
* Insulin: Banyak nilai 0 (kemungkinan data kosong/tidak diukur), dan selebihnya tersebar dari 0 hingga >300. Puncak setelah 0 ada di kisaran 100â€“200.
* BMI: Mayoritas indeks massa tubuh berada di kisaran 25â€“40, dengan puncak sekitar 30â€“35. Artinya sebagian besar tergolong kelebihan berat badan atau obesitas ringan.
* DiabetesPedigreeFunction: Mayoritas memiliki nilai di bawah 0.5, dengan puncak antara 0.1â€“0.3. Ini menunjukkan mayoritas peserta memiliki riwayat diabetes keluarga yang rendah hingga sedang.
* Age: Mayoritas peserta berusia 20â€“40 tahun, dengan puncak sekitar 20â€“30 tahun.
* Outcome (Diabetes):Mayoritas responden tidak menderita diabetes (nilai 0), sedangkan sebagian kecil (sekitar 1/3) memiliki diabetes (nilai 1).

Mengecek jumlah outlier pada setiap kolom di DataFrame menggunakan metode IQR
"""

# Deteksi Outlier dengan metode IQR
def detect_outliers(data):
    outlier_summary = {}
    for column in data.select_dtypes(include=np.number).columns:
        Q1 = data[column].quantile(0.25)
        Q3 = data[column].quantile(0.75)
        IQR = Q3 - Q1
        lower_bound = Q1 - 1.5 * IQR
        upper_bound = Q3 + 1.5 * IQR
        outliers = data[(data[column] < lower_bound) | (data[column] > upper_bound)]
        outlier_summary[column] = len(outliers)

    return outlier_summary

# Menjalankan fungsi untuk dataset (tanpa kolom target)
indicators_columns = df.drop(columns=['Outcome'], errors='ignore')
outlier_counts = detect_outliers(indicators_columns)

# Menampilkan jumlah outlier per kolom
print("Jumlah outlier per kolom:")
for col, count in outlier_counts.items():
    print(f"{col}: {count}")

"""Hasil deteksi outlier menunjukkan bahwa kolom BloodPressure memiliki jumlah outlier terbanyak (45), diikuti oleh Insulin (34) dan DiabetesPedigreeFunction (29). Kolom seperti Pregnancies, Glucose, BMI, dan Age juga memiliki sejumlah outlier, meskipun lebih sedikit. Sementara itu, tidak ditemukan outlier pada kolom Outcome, menandakan distribusi label target cukup konsisten.

Mengelompokkan fitur numerik kecuali kolom target 'outcome'
"""

indicators_feature = df.select_dtypes(include=np.number).drop(columns=['Outcome'], errors='ignore').columns

"""menampilkan visualisasi outlier dari masing-masing kolom"""

import math

# Hitung jumlah baris dan kolom dinamis (misalnya grid 4x2 atau 3x4 tergantung jumlah fitur)
n_features = len(indicators_feature)
n_cols = 2
n_rows = math.ceil(n_features / n_cols)

# Buat grid
fig, axes = plt.subplots(nrows=n_rows, ncols=n_cols, figsize=(12, n_rows * 3))
fig.suptitle('Boxplot of Numerical Features', fontsize=16)

# Flatten axes supaya bisa di-loop
axes = axes.flatten()

# Plot tiap fitur
for i, feature in enumerate(indicators_feature):
    sns.boxplot(data=df, x=feature, ax=axes[i])
    axes[i].set_title(f'{feature}')
    axes[i].set_xlabel('')

# Sembunyikan subplot kosong
for j in range(len(indicators_feature), len(axes)):
    fig.delaxes(axes[j])

plt.tight_layout(rect=[0, 0, 1, 0.96])
plt.show()

"""Menghapus outlier dengan metode IQR"""

# Fungsi untuk menghapus outlier dengan metode IQR
df_clean = df.copy()
def remove_outliers(df, columns):
    df_clean = df.copy()
    for col in columns:
        Q1 = df_clean[col].quantile(0.25)
        Q3 = df_clean[col].quantile(0.75)
        IQR = Q3 - Q1
        lower_bound = Q1 - 1.5 * IQR
        upper_bound = Q3 + 1.5 * IQR
        df_clean = df_clean[(df_clean[col] >= lower_bound) & (df_clean[col] <= upper_bound)]
    return df_clean

# Hapus outlier
df_clean = remove_outliers(df_clean, indicators_feature)

# Tampilkan informasi perubahan
print("Outlier Berhasil Dihapus")

print(f"Jumlah baris sebelum data cleansing: {df.shape[0]}")
print(f"Jumlah baris sesudah data cleansing: {df_clean.shape[0]}")

"""Setelah penghapusan outline menggunakan metode IQR jumlah baris menjadi berkurang dari jumlah baris sebelum data cleansing adalah 768 menjadi 636 Jumlah baris sesudah data cleansing

## Train-test split

Melakukan Train-test split data sebelum pelatihan model
"""

from sklearn.model_selection import train_test_split
from sklearn.preprocessing import MinMaxScaler
from sklearn.decomposition import PCA
from imblearn.over_sampling import SMOTE

X = df_clean.drop(columns=["Outcome"])
y = df_clean["Outcome"]

scaler = MinMaxScaler()
X_scaler = scaler.fit_transform(X)

smote = SMOTE(random_state=42)
X_resampled, y_resampled = smote.fit_resample(X_scaler, y)

pca = PCA(n_components= 0.95)
X_pca = pca.fit_transform(X_resampled)

X_train, X_test, y_train, y_test = train_test_split(X_pca, y_resampled, test_size= 0.2, random_state= 42)

print(f'Total # of sample in train dataset: {len(X_train)}')
print(f'Total # of sample in test dataset: {len(X_test)}')

"""Pada tahap Preperation dilakukan proses berikut:

*   MinMaxScaler untuk menormalkan fitur ke rentang [0, 1]
*   SMOTE untuk mengatasi ketidakseimbangan kelas dengan oversampling
*   PCA untuk mereduksi dimensi dengan mempertahankan 95% variansi
*   Data dibagi menjadi data latih dan data uji dengan rasio 80:20

Berdasarkan hasil preprocessing, data telah dinormalisasi, diseimbangkan, direduksi dimensinya, dan dibagi menjadi data pelatihan dan pengujian sehingga siap untuk pelatihan model machine learning.

# Training Model

Pada tahap ini, kita akan mengembangkan model machine learning dengan dua algoritma. Kemudian, kita akan mengevaluasi performa masing-masing algoritma dan menentukan algoritma mana yang memberikan hasil prediksi terbaik. Kedua algoritma yang akan kita gunakan, antara lain:

- Random Forest
- Decission Tree

## Random Forest

Melatih model Random Forest dan mengevaluasi performanya
"""

from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import accuracy_score, classification_report
from sklearn.model_selection import cross_val_score

rf = RandomForestClassifier(n_estimators=100, max_depth=10,
                           min_samples_leaf=5, random_state=42)
rf.fit(X_train, y_train)
y_train_rf = rf.predict(X_train)
y_test_rf = rf.predict(X_test)
train_acc = accuracy_score(y_train, y_train_rf)
test_acc = accuracy_score(y_test, y_test_rf)
cv_scores = cross_val_score(rf, X_train, y_train, cv=5)

print(f"Accuracy Data Training: {train_acc:.2f}")
print(f"Accuracy Data Testing: {test_acc:.2f}")
print(f"Mean CV Score:{cv_scores.mean():.2f}")
print(classification_report(y_test, y_test_rf))

"""Berdasarkan model random forest tersebut dapat diketahui bahwa:

*   Random Forest dengan 100 estimator, batas kedalaman 10, dan minimal 5 sampel per daun
*   Akurasi training: 0.93, testing: 0.79, validasi silang rata-rata: 0.80
*   Performa seimbang antara precision dan recall untuk kedua kelas
*   Classification report menunjukkan F1-score sebesar 0.79 untuk kedua kelas

âœ… Kesimpulan:
Model Random Forest menunjukkan performa yang baik dengan akurasi data testing sebesar 0.79, tidak jauh berbeda dari skor validasi silang. Ini mengindikasikan bahwa model cukup general dan tidak overfitting. Precision dan recall seimbang untuk kedua kelas, menjadikannya cocok untuk digunakan dalam kasus klasifikasi biner seperti prediksi diabetes.

## Decission Tree

Melatih model Decission Tree dan mengevaluasi performanya
"""

from sklearn.tree import DecisionTreeClassifier
from sklearn.metrics import confusion_matrix

dt = DecisionTreeClassifier(max_depth=10, random_state=42)
dt.fit(X_train, y_train)
y_train_dt = dt.predict(X_train)
y_test_dt = dt.predict(X_test)

train_acc_dt = accuracy_score(y_train, y_train_dt)
test_acc_dt = accuracy_score(y_test, y_test_dt)
cv_scores_dt = cross_val_score(dt, X_train, y_train, cv=5)

print(f"Accuracy Data Training: {train_acc_dt:.2f}")
print(f"Accuracy Data Testing: {test_acc_dt:.2f}")
print(f"Mean CV Score:{cv_scores_dt.mean():.2f}")
print(classification_report(y_test, y_test_dt))

"""Berdasarkan model Desiccion Tree tersebut dapat diketahui bahwa:
*   Decision Tree dengan maksimal kedalaman 10
*   Akurasi training: 0.97, testing: 0.78, validasi silang rata-rata: 0.77
*   F1-score untuk kelas 0 dan 1 seimbang, sekitar 0.78â€“0.79
*   Recall tinggi pada kelas 1 (0.83), berguna untuk deteksi kasus positif

âœ… Kesimpulan:
Model Decision Tree memiliki akurasi training yang sangat tinggi (0.97) namun menurun pada data testing (0.78), menunjukkan kemungkinan overfitting.
Namun, metrik klasifikasi menunjukkan performa yang masih seimbang dan layak digunakan, terutama jika fokus pada recall untuk kasus positif. Skor validasi silang sebesar 0.77 mendukung konsistensi model pada data baru.

# Perbandingan Model

Perbandingan akurasi model
"""

acc_rf = accuracy_score(y_test, y_test_rf)
acc_dt = accuracy_score(y_test, y_test_dt)

print(f"Akurasi Random Forest: {acc_rf:.3f}")
print(f"Akurasi Decision Tree: {acc_dt:.3f}")

"""Visualisasi erbandingan akurasi model"""

from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score

# Dictionary untuk menyimpan hasil evaluasi
model_scores = {}

# Fungsi evaluasi dan pencatatan skor
def evaluate_and_store(model, X_train, y_train, X_test, y_test, model_name):
    model.fit(X_train, y_train)
    y_pred = model.predict(X_test)

    # Simpan skor dalam dictionary
    model_scores[model_name] = {
        'Accuracy': accuracy_score(y_test, y_pred),
        'Precision': precision_score(y_test, y_pred, average='macro'),
        'Recall': recall_score(y_test, y_pred, average='macro'),
        'F1 Score': f1_score(y_test, y_pred, average='macro')
    }

# Evaluasi semua model
from sklearn.ensemble import RandomForestClassifier
from sklearn.tree import DecisionTreeClassifier

# Random Forest
rf_model = RandomForestClassifier(random_state=42)
evaluate_and_store(rf_model, X_train, y_train, X_test, y_test, "Random Forest")

# Decision Tree
dt_model = DecisionTreeClassifier(random_state=42)
evaluate_and_store(dt_model, X_train, y_train, X_test, y_test, "Decision Tree")

# Menampilkan hasil perbandingan
import pandas as pd

results_df = pd.DataFrame(model_scores).T
results_df = results_df.sort_values(by="Accuracy", ascending=False)  # Urutkan berdasarkan akurasi
print("ğŸ“Š Hasil Perbandingan Model:\n")
print(results_df)

# Opsional: visualisasi
import seaborn as sns
import matplotlib.pyplot as plt

plt.figure(figsize=(10, 6))
sns.barplot(data=results_df.reset_index().melt(id_vars='index'), x='index', y='value', hue='variable')
plt.title("Perbandingan Performa Model")
plt.xlabel("Model")
plt.ylabel("Skor")
plt.xticks(rotation=45)
plt.legend(title="Metric")
plt.tight_layout()
plt.show()

"""Dari keempat diagram, Decision Tree mengungguli Random Forest dalam seluruh aspek. Hal ini menjadikan Decision Tree sebagai model yang lebih baik secara keseluruhan.

Model Decision Tree adalah model terbaik dalam studi ini karena mampu memberikan:


*  Akurasi yang tinggi
*  Precision yang sangat baik
*   Keseimbangan recall dan F1 score

# Fitur

## Prediksi hasil diabetes berdasarkan inputan yang diberikan
"""

import numpy as np
import pandas as pd

def infer_diabetes_risk(model, scaler, pca):
    print("Masukkan data berikut untuk memprediksi risiko diabetes Anda:\n")

    try:
        pregnancies = int(input("Jumlah kehamilan: "))
        glucose = float(input("Kadar glukosa darah (mg/dL): "))
        blood_pressure = float(input("Tekanan darah (mm Hg): "))
        skin_thickness = float(input("Ketebalan lipatan kulit triceps (mm): "))
        insulin = float(input("Kadar insulin (mu U/ml): "))
        bmi = float(input("BMI (Indeks Massa Tubuh): "))
        dpf = float(input("Fungsi silsilah diabetes (Diabetes Pedigree Function): "))
        age = int(input("Usia: "))

        fitur_input = pd.DataFrame([[
            pregnancies, glucose, blood_pressure, skin_thickness,
            insulin, bmi, dpf, age
        ]], columns=[
            'Pregnancies', 'Glucose', 'BloodPressure', 'SkinThickness',
            'Insulin', 'BMI', 'DiabetesPedigreeFunction', 'Age'
        ])

        fitur_input_scaled = scaler.transform(fitur_input)
        fitur_input_pca = pca.transform(fitur_input_scaled)

        pred_label = model.predict(fitur_input_pca)

        hasil = "Positif (berisiko)" if pred_label[0] == 1 else "Negatif (tidak berisiko)"
        print("\nğŸ“Š Prediksi hasil diabetes Anda adalah:", hasil)

    except ValueError:
        print("Input tidak valid. Pastikan Anda memasukkan angka.")
    except Exception as e:
        print(f"Terjadi kesalahan: {e}")

infer_diabetes_risk(dt_model, scaler, pca)

"""## Korelasi antar fitur numerik dengan hasil yang didapat"""

# Hitung korelasi antar fitur numerik terhadap 'Outcome'
correlation_matrix = df_clean.corr(numeric_only=True)
cor_target = correlation_matrix['Outcome'].drop('Outcome').sort_values(ascending=False)

print("ğŸ“Š Korelasi fitur terhadap 'Outcome':")
print(cor_target)

# Ambil fitur dengan korelasi absolut > 0.3
important_features = cor_target[cor_target.abs() > 0.25]
print("\nğŸ”¥ Fitur dengan pengaruh signifikan (|korelasi| > 0.3):")
print(important_features)